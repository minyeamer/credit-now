{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, utils\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "import keras_tuner as kt\n",
    "\n",
    "import credit_data\n",
    "import visualkeras\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15906, 67) (6818, 67) (15906, 3) (6818, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_label, test_label = credit_data.load_data()\n",
    "\n",
    "train_data = train_data.todense()\n",
    "test_data = test_data.todense()\n",
    "train_label = utils.to_categorical(train_label)\n",
    "test_label = utils.to_categorical(test_label)\n",
    "\n",
    "print(train_data.shape, test_data.shape, train_label.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b2M1Op-Hb7uI"
   },
   "outputs": [],
   "source": [
    "def build_hyper_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    hp_units = hp.Int('units_input', min_value=32, max_value=512, step=32)\n",
    "    hp_activations = hp.Choice('activation_input', values=['relu', 'elu'])\n",
    "    model.add(layers.Dense(input_dim=67, units=hp_units, activation=hp_activations, kernel_initializer=he_uniform()))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    for layer_num in range(hp.Int('num_layers', min_value=1, max_value=5)): \n",
    "        hp_units = hp.Int('units_' + str(layer_num), min_value=32, max_value=512, step=32)\n",
    "        hp_activations = hp.Choice('activation_' + str(layer_num), values=['relu', 'elu'])\n",
    "        model.add(layers.Dense(hp_units, activation=hp_activations, kernel_initializer=he_uniform()))\n",
    "        hp_dropouts = hp.Float('dropout_' + str(layer_num), 0.1, 0.5, step=0.1)\n",
    "        model.add(layers.Dropout(hp_dropouts))\n",
    "        model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "    model.compile(optimizer=Adam(hp_learning_rate),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uYthW2b6fiP",
    "outputId": "164fb118-ee7c-4925-b136-9b7e093b2b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project keras_tuner/model_hyper/oracle.json\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "INFO:tensorflow:Reloading Tuner from keras_tuner/model_hyper/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 16\n",
      "units_input (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "activation_input (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "activation_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n",
      "dropout_0 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "activation_1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "activation_2 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "activation_3 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n",
      "dropout_3 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.BayesianOptimization(build_hyper_model,\n",
    "                                objective = 'val_accuracy',\n",
    "                                max_trials = 1000,\n",
    "                                directory = 'keras_tuner',\n",
    "                                project_name = 'model_hyper')\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXSCIHWE6j_2",
    "outputId": "c20d6898-0221-4346-a420-84b7023e552f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 Complete [00h 01m 24s]\n",
      "val_accuracy: 0.6629510521888733\n",
      "\n",
      "Best val_accuracy So Far: 0.6911118030548096\n",
      "Total elapsed time: 00h 36m 40s\n",
      "\n",
      "Search: Running Trial #25\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "192               |512               |units_input\n",
      "elu               |elu               |activation_input\n",
      "5                 |2                 |num_layers\n",
      "32                |32                |units_0\n",
      "relu              |relu              |activation_0\n",
      "0.4               |0                 |dropout_0\n",
      "0.01              |0.01              |learning_rate\n",
      "512               |512               |units_1\n",
      "elu               |elu               |activation_1\n",
      "0.3               |0.5               |dropout_1\n",
      "448               |288               |units_2\n",
      "elu               |elu               |activation_2\n",
      "0.4               |0.4               |dropout_2\n",
      "224               |32                |units_3\n",
      "elu               |elu               |activation_3\n",
      "0                 |0                 |dropout_3\n",
      "128               |32                |units_4\n",
      "elu               |elu               |activation_4\n",
      "0.5               |0.5               |dropout_4\n",
      "\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 11s 50ms/step - loss: 0.9511 - accuracy: 0.6091 - val_loss: 0.8686 - val_accuracy: 0.6522\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 6s 40ms/step - loss: 0.8793 - accuracy: 0.6474 - val_loss: 0.8460 - val_accuracy: 0.6674\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 14s 88ms/step - loss: 0.8574 - accuracy: 0.6635 - val_loss: 0.8903 - val_accuracy: 0.6533\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 12s 71ms/step - loss: 0.8441 - accuracy: 0.6742 - val_loss: 0.8266 - val_accuracy: 0.6813\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 22s 138ms/step - loss: 0.8333 - accuracy: 0.6810 - val_loss: 0.8367 - val_accuracy: 0.6786\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 12s 73ms/step - loss: 0.8301 - accuracy: 0.6822 - val_loss: 0.8528 - val_accuracy: 0.6776\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 17s 107ms/step - loss: 0.8264 - accuracy: 0.6848 - val_loss: 0.8182 - val_accuracy: 0.6872\n",
      "Epoch 8/10\n",
      "115/160 [====================>.........] - ETA: 2s - loss: 0.8228 - accuracy: 0.6868"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/cuz/Documents/Github/credit-now/keras_tuner.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cuz/Documents/Github/credit-now/keras_tuner.ipynb#ch0000006?line=0'>1</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(train_data, train_label, batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(test_data, test_label))\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py?line=175'>176</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py?line=177'>178</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py?line=178'>179</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py?line=179'>180</a>\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py?line=180'>181</a>\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:294\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py?line=291'>292</a>\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py?line=292'>293</a>\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py?line=293'>294</a>\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py?line=295'>296</a>\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py?line=296'>297</a>\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py?line=219'>220</a>\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py?line=220'>221</a>\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py?line=221'>222</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py?line=222'>223</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tuner_utils\u001b[39m.\u001b[39mconvert_to_metrics_dict(\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py?line=223'>224</a>\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py?line=224'>225</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:137\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py?line=112'>113</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py?line=113'>114</a>\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py?line=114'>115</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py?line=115'>116</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py?line=134'>135</a>\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py?line=135'>136</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py?line=136'>137</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///Users/cuz/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(train_data, train_label, batch_size=100, epochs=10, validation_data=(test_data, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDlJzL14GVXR",
    "outputId": "bc282bbd-e3cb-4178-ab01-64a2d89e2f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in test_prac_dir/MNIST_hyper_1\n",
      "Showing 3 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 512\n",
      "activation_0: relu\n",
      "learning_rate: 0.0001\n",
      "units_1: 512\n",
      "activation_1: relu\n",
      "units_2: 32\n",
      "activation_2: relu\n",
      "Score: 0.9772999882698059\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 512\n",
      "activation_0: elu\n",
      "learning_rate: 0.0001\n",
      "units_1: 512\n",
      "activation_1: elu\n",
      "units_2: 32\n",
      "activation_2: relu\n",
      "Score: 0.9736999869346619\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 512\n",
      "activation_0: elu\n",
      "learning_rate: 0.0001\n",
      "units_1: 32\n",
      "activation_1: relu\n",
      "units_2: 32\n",
      "activation_2: relu\n",
      "Score: 0.9715999960899353\n"
     ]
    }
   ],
   "source": [
    "# 5) Check the result \n",
    "\n",
    "tuner.results_summary(num_trials=3) # Show \"n\" best trial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFbk0Bvo36HR",
    "outputId": "9f835481-18d7-4967-92b5-c217e76daedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance rank : 0\n",
      "{'num_layers': 1, 'units_0': 512, 'activation_0': 'relu', 'learning_rate': 0.0001, 'units_1': 512, 'activation_1': 'relu', 'units_2': 32, 'activation_2': 'relu'}\n",
      "\n",
      "Model performance rank : 1\n",
      "{'num_layers': 3, 'units_0': 512, 'activation_0': 'elu', 'learning_rate': 0.0001, 'units_1': 512, 'activation_1': 'elu', 'units_2': 32, 'activation_2': 'relu'}\n",
      "\n",
      "Model performance rank : 2\n",
      "{'num_layers': 3, 'units_0': 512, 'activation_0': 'elu', 'learning_rate': 0.0001, 'units_1': 32, 'activation_1': 'relu', 'units_2': 32, 'activation_2': 'relu'}\n",
      "\n",
      "\n",
      "The hyperparameter search is complete. \n",
      "* Optimal # of layers : 1\n",
      "* Optimal value of the learning-rate : 0.0001\n",
      "Layer 0 - # of Perceptrons : 512\n",
      "Layer 0 - Applied activation function : relu\n"
     ]
    }
   ],
   "source": [
    "# Check top-3 trials' hyper-params\n",
    "\n",
    "top3_models = tuner.get_best_hyperparameters(num_trials=3)\n",
    "# print(tuner.get_best_hyperparameters(num_trials=3)[0].space) # 특정 Trial의 Search-space 를 확인할 수 있음\n",
    "# print(tuner.get_best_hyperparameters(num_trials=3)[0].values) # 특정 Trial에 적용된 Hyper-params를 확인할 수 있음\n",
    "\n",
    "for idx, model in enumerate(top3_models):\n",
    "    print('Model performance rank :', idx)\n",
    "    print(model.values)\n",
    "    print()\n",
    "\n",
    "\n",
    "# Check the best trial's hyper-params\n",
    "\n",
    "best_hps = top3_models[0]\n",
    "\n",
    "print(\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "* Optimal # of layers : {}\n",
    "* Optimal value of the learning-rate : {}\"\"\".format(best_hps.get('num_layers'), best_hps.get('learning_rate')))\n",
    "\n",
    "for layer_num in range(best_hps.get('num_layers')):\n",
    "    print('Layer {} - # of Perceptrons :'.format(layer_num), best_hps.get('units_' + str(layer_num)))\n",
    "    print('Layer {} - Applied activation function :'.format(layer_num), best_hps.get('activation_' + str(layer_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oO2QFJn0L7z_",
    "outputId": "a90701e0-f12c-41b0-ac7f-35355e5f7f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0770 - accuracy: 0.9773\n",
      "Cross-entropy : 0.07701890170574188\n",
      "Accuracy : 0.9772999882698059\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from trials\n",
    "\n",
    "models = tuner.get_best_models(num_models=3) # Keras Sequential models\n",
    "top_model = models[0]\n",
    "top_model.summary()\n",
    "print()\n",
    "\n",
    "results = top_model.evaluate(x_test, y_test)\n",
    "print('Cross-entropy :', results[0])\n",
    "print('Accuracy :', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3j5xYX3dOHqV",
    "outputId": "ab3c7d96-0ae8-41e7-f6f7-0eb96014f5fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4527 - accuracy: 0.8856 - val_loss: 0.2434 - val_accuracy: 0.9318\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2154 - accuracy: 0.9410 - val_loss: 0.1819 - val_accuracy: 0.9477\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1624 - accuracy: 0.9550 - val_loss: 0.1454 - val_accuracy: 0.9579\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1301 - accuracy: 0.9643 - val_loss: 0.1224 - val_accuracy: 0.9649\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1077 - accuracy: 0.9705 - val_loss: 0.1065 - val_accuracy: 0.9694\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0908 - accuracy: 0.9755 - val_loss: 0.0984 - val_accuracy: 0.9713\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0778 - accuracy: 0.9792 - val_loss: 0.0884 - val_accuracy: 0.9737\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0675 - accuracy: 0.9820 - val_loss: 0.0822 - val_accuracy: 0.9764\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0590 - accuracy: 0.9846 - val_loss: 0.0764 - val_accuracy: 0.9765\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0524 - accuracy: 0.9864 - val_loss: 0.0744 - val_accuracy: 0.9768\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0744 - accuracy: 0.9768\n",
      "Cross-entropy : 0.07435154914855957\n",
      "Accuracy : 0.9768000245094299\n"
     ]
    }
   ],
   "source": [
    "# We can retrain the model with the optimal hyperparameters from the search.\n",
    "best_hps = top3_models[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data.\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print('Cross-entropy :', results[0])\n",
    "print('Accuracy :', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N53W-VP4X_6Y",
    "outputId": "235f6b17-705d-421e-ad9d-2d8b84f3aee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial-score is : 0.9772999882698059\n",
      "Trial-directory(trial_id) is : ae3157b4a53b4b81dbf4907fb9a81d78\n",
      "\n",
      "Trial-score is : 0.9736999869346619\n",
      "Trial-directory(trial_id) is : 4176b5ee8939bdf6add6abc59d7b1bfa\n",
      "\n",
      "Trial-score is : 0.9715999960899353\n",
      "Trial-directory(trial_id) is : 6c4fd68fcba615c0504886a18afbe0f9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also find detailed logs, checkpoints, etc, in the folder \"directory/project_name\".\n",
    "\n",
    "# The [test_prac_dir/MNIST_hyper_1] directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. \n",
    "# If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. \n",
    "# To disable this behavior, pass an additional [overwrite = True] argument while instantiating the tuner.\n",
    "\n",
    "for trial in tuner.oracle.get_best_trials(num_trials=3):\n",
    "    print('Trial-score is :', trial.score)\n",
    "    print('Trial-directory(trial_id) is :', trial.trial_id)\n",
    "    print()\n",
    "\n",
    "# tuner.oracle.trials -> get all trial_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 8s 27ms/step - loss: 0.7800 - accuracy: 0.6900 - val_loss: 0.8296 - val_accuracy: 0.6789\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 4s 27ms/step - loss: 0.7669 - accuracy: 0.6936 - val_loss: 0.8226 - val_accuracy: 0.6888\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 3s 21ms/step - loss: 0.7539 - accuracy: 0.7006 - val_loss: 0.8272 - val_accuracy: 0.6760\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 3s 20ms/step - loss: 0.7489 - accuracy: 0.7007 - val_loss: 0.8252 - val_accuracy: 0.6797\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 3s 19ms/step - loss: 0.7411 - accuracy: 0.7030 - val_loss: 0.8277 - val_accuracy: 0.6866\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 3s 21ms/step - loss: 0.7345 - accuracy: 0.7051 - val_loss: 0.8349 - val_accuracy: 0.6806\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 3s 20ms/step - loss: 0.7222 - accuracy: 0.7114 - val_loss: 0.8388 - val_accuracy: 0.6773\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 3s 19ms/step - loss: 0.7169 - accuracy: 0.7104 - val_loss: 0.8406 - val_accuracy: 0.6788\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 3s 19ms/step - loss: 0.7105 - accuracy: 0.7105 - val_loss: 0.8528 - val_accuracy: 0.6785\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 3s 21ms/step - loss: 0.6971 - accuracy: 0.7184 - val_loss: 0.8350 - val_accuracy: 0.6857\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 0.8350 - accuracy: 0.6857\n",
      "Cross-entropy : 0.8350167274475098\n",
      "Accuracy : 0.6856849789619446\n"
     ]
    }
   ],
   "source": [
    "top_model = models.load_model('keras_tuner/top_model.h5')\n",
    "top_model.fit(train_data, train_label, batch_size=100, epochs=10, validation_data=(test_data, test_label))\n",
    "\n",
    "results = top_model.evaluate(test_data, test_label)\n",
    "print('Cross-entropy :', results[0])\n",
    "print('Accuracy :', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtqkwnj_ncpy"
   },
   "source": [
    "<br> \n",
    "\n",
    "## (Appendix) Use pre-trained models for computer vision: HyperResNet & HyperXception\n",
    "\n",
    "* pre-compiled with loss='categorical_crossentropy' & metrics=\\['accuracy']\n",
    "* Next model-trainings take too much time, so try it if you are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kc5odBmRnZZx"
   },
   "outputs": [],
   "source": [
    "from kerastuner.applications import HyperResNet, HyperXception\n",
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner import HyperParameters\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# (img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data() # if you want to use Fashion-MNIST instead of MNIST\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Prepare the data as needed\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7Wwwyo7b7ni"
   },
   "source": [
    "### Pre-trained ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CAnREsBfdhb"
   },
   "outputs": [],
   "source": [
    "hypermodel = HyperResNet(input_shape=(28, 28, 1), classes=10)\n",
    "\n",
    "# Hyperband performs better than random search with low level computing resource. (Hyperband @ https://arxiv.org/abs/1603.06560)\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=40,\n",
    "    directory='test_prac_dir',\n",
    "    project_name='MNIST_Resnet_1')\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTzEeWQOcATX"
   },
   "source": [
    "### Pre-trained Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CYJdQdeh8Xj"
   },
   "outputs": [],
   "source": [
    "hypermodel = HyperXception(input_shape=(28, 28, 1), classes=10)\n",
    "\n",
    "# This will override the `learning_rate` parameter with your own selection of choices\n",
    "hp = HyperParameters()\n",
    "hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "# we can easily restrict the search space to just a few parameters\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    hyperparameters=hp, # ADDED\n",
    "    tune_new_entries=False, # ADDED (`tune_new_entries=False` prevents unlisted parameters from being tuned)\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=40,\n",
    "    directory='test_prac_dir',\n",
    "    project_name='MNIST_Xception_1')\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "tuner.results_summary()\n",
    "\n",
    "# What if you want to tune all available parameters in a hypermodel except the learning rate? @ https://j.mp/2J7jzHj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnupwN59cRnt"
   },
   "source": [
    "### Changing the existing optimizer, loss, or metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5HQ0PcYh0bv"
   },
   "outputs": [],
   "source": [
    "hypermodel = HyperXception(input_shape=(28, 28, 1), classes=10)\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss='mse',\n",
    "    metrics=[keras.metrics.Precision(name='precision'),\n",
    "             keras.metrics.Recall(name='recall')],\n",
    "    objective='mse',\n",
    "    max_epochs=40,\n",
    "    directory='test_prac_dir',\n",
    "    project_name='MNIST_Xception_1')\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a71a6a35a5e2082b4baf2330a569e10365064de6ba0b0fb1962d72bc015b0efc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
